{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "509d5a1e-10f2-4294-a104-9fdb85a29b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sparkuser/.conda/envs/cpu_pr/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-04-01 01:56:50,465\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-01 01:56:50 pynccl_utils.py:17] Failed to import NCCL library: NCCL only supports CUDA and ROCm backends.\n",
      "INFO 04-01 01:56:50 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.\n",
      "INFO 04-01 01:56:50 llm_engine.py:75] Initializing an LLM engine (v0.4.0) with config: model='defog/sqlcoder-34b-alpha', tokenizer='defog/sqlcoder-34b-alpha', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=16384, download_dir='/mnt/DP_disk2/models/Huggingface/', load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cpu, seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 04-01 01:56:50 cpu_executor.py:96] float16 is not supported on CPU, casting to bfloat16.\n",
      "WARNING 04-01 01:56:50 cpu_executor.py:100] CUDA graph is not supported on CPU, fallback to the eager mode.\n",
      "WARNING 04-01 01:56:50 utils.py:357] Pin memory is not supported on CPU.\n",
      "INFO 04-01 01:56:50 selector.py:21] Using Torch SDPA backend.\n",
      "INFO 04-01 01:56:51 weight_utils.py:177] Using model weights format ['*.bin']\n",
      "INFO 04-01 01:57:11 cpu_executor.py:69] # CPU blocks: 1365, # GPU blocks: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO: \u001b[0mThe pyspark.sql.connect.dataframe module could not be imported. This might be due to your PySpark version being below 3.4.\n",
      "-------------------------Start get_transform_sql_query-------------------------\n",
      "\n",
      "\n",
      "\u001b[92mINFO: \u001b[0mCreating temp view for the transform:\n",
      "df.createOrReplaceTempView(\u001b[33m\"\u001b[39;49;00m\u001b[33mspark_ai_temp_view__2114715937\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\n",
      "-------------------------Current table schema from df is:-------------------------\n",
      "\n",
      " product, string\n",
      "category, string\n",
      "revenue, bigint\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sparkuser/.conda/envs/cpu_pr/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `predict_messages` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Current sample vals are:-------------------------\n",
      "\n",
      " (product, string, ['Normal', 'Normal', 'Mini'])\n",
      "(category, string, ['Cellphone', 'Tablet', 'Tablet'])\n",
      "(revenue, bigint, ['6000', '1500', '5500'])\n",
      "\n",
      "-------------------------Current table comment is-------------------------\n",
      "\n",
      " \n",
      "\n",
      "-------------------------Start generating sql query with a prompt with few-shot examples-------------------------\n",
      "\n",
      "\n",
      "-------------------------Input prompt is:-------------------------\n",
      "\n",
      " You are an assistant for writing professional Spark SQL queries. \n",
      "Given a question, you need to write a Spark SQL query to answer the question.\n",
      "The rules that you should follow for answering question:\n",
      "1.The answer only consists of Spark SQL query. No explaination. No \n",
      "2.SQL statements should be  Spark SQL query.\n",
      "3.ONLY use the verbatim column_name in your resulting SQL query; DO NOT include the type.\n",
      "4.Use the COUNT SQL function when the query asks for total number of some non-countable column.\n",
      "5.Use the SUM SQL function to accumulate the total number of countable column values.\n",
      "\n",
      "QUESTION: Given a Spark temp view `spark_ai_temp_view_14kjd0` with the following sample vals,\n",
      "    in the format (column_name, type, [sample_value_1, sample_value_2...]):\n",
      "```\n",
      "(a, string, [Kongur Tagh, Grossglockner])\n",
      "(b, int, [7649, 3798])\n",
      "(c, string, [China, Austria])\n",
      "```\n",
      "Write a Spark SQL query to retrieve from view `spark_ai_temp_view_14kjd0`: Find the mountain located in Japan.\n",
      "Answer:\n",
      "```SELECT `a` FROM `spark_ai_temp_view_14kjd0` WHERE `c` = 'Japan'```\n",
      "\n",
      "QUESTION: Given a Spark temp view `spark_ai_temp_view_12qcl3` with the following (columns, types, sample_values):\n",
      "```\n",
      "(Student, string, [student1, student2])\n",
      "(Birthday, string, [Dec 12 2005, 2006-03-04])\n",
      "```\n",
      "Write a Spark SQL query to retrieve from view `spark_ai_temp_view_12qcl3`: What is the total number of students with the birthday January 1, 2006?\n",
      "\n",
      "Answer:\n",
      "```SELECT COUNT(`Student`) FROM `spark_ai_temp_view_12qcl3` WHERE `Birthday` = 'January 1, 2006'```\n",
      "\n",
      "\n",
      "Question: Given a Spark temp view `spark_ai_temp_view__2114715937`  with the following sample vals,\n",
      " in the format (column_name, type, [sample_value_1, sample_value_2...]):\n",
      "```\n",
      "(product, string, ['Normal', 'Normal', 'Mini'])\n",
      "(category, string, ['Cellphone', 'Tablet', 'Tablet'])\n",
      "(revenue, bigint, ['6000', '1500', '5500'])\n",
      "```\n",
      "Write a Spark SQL query to retrieve from view `spark_ai_temp_view__2114715937`: What is the best-selling product\n",
      "Answer:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████████████████████████| 1/1 [00:19<00:00, 19.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------The model replies:-------------------------\n",
      "\n",
      " ```SELECT product, SUM(revenue) AS total_revenue FROM `spark_ai_temp_view__2114715937` GROUP BY product``` \n",
      "\n",
      "-------------------------Spark retrieved sql:-------------------------\n",
      "\n",
      " SELECT product, SUM(revenue) AS total_revenue FROM `spark_ai_temp_view__2114715937` GROUP BY product\n",
      "\n",
      "-------------------------End get_transform_sql_query-------------------------\n",
      "\n",
      " get_transform_sql_query_time: 20.60026216506958 seconds\n",
      "\n",
      "-------------------------Received query:-------------------------\n",
      "\n",
      " SELECT product, SUM(revenue) AS total_revenue FROM `spark_ai_temp_view__2114715937` GROUP BY product\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+\n",
      "| product|total_revenue|\n",
      "+--------+-------------+\n",
      "|  Normal|         7500|\n",
      "|    Mini|        10500|\n",
      "|Foldable|         9000|\n",
      "|     Pro|         7000|\n",
      "| Pro Max|         4500|\n",
      "+--------+-------------+\n",
      "\n",
      "Init time: 23.6774263381958 seconds\n",
      "Task time: 22.08994436264038 seconds\n"
     ]
    }
   ],
   "source": [
    "# Restart kernel before running\n",
    "\n",
    "import os\n",
    "import time\n",
    "from langchain_community.llms import VLLM\n",
    "from pyspark_ai import SparkAI\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ['OMP_NUM_THREADS'] = '32'\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize the VLLM\n",
    "llm = VLLM(\n",
    "    #optional models\n",
    "    #defog/sqlcoder-70b-alpha 93.0%\n",
    "    #defog/sqlcoder-7b-2      90.5%\n",
    "    #defog/sqlcoder-34b-alpha 84.0%\n",
    "    #defog/sqlcoder2          74.5%\n",
    "    #defog/sqlcoder-7b        71.0%\n",
    "    #defog/sqlcoder           64.6%\n",
    "    model=\"deepseek-ai/deepseek-coder-7b-instruct-v1.5\",\n",
    "    trust_remote_code=True,\n",
    "    download_dir=\"/mnt/DP_disk2/models/Huggingface/\", #~/.conda/envs/zedong-vllm/lib/python3.10/site-packages/langchain_community/llms/vllm.py:88\n",
    ")\n",
    "\n",
    "# Initialize and activate SparkAI\n",
    "spark_ai = SparkAI(llm=llm,verbose=True)\n",
    "spark_ai.activate()\n",
    "\n",
    "init_time = time.time() - start_time\n",
    "\n",
    "# create a dataframe productRevenue\n",
    "df = spark_ai._spark.createDataFrame(\n",
    "    [\n",
    "        (\"Normal\", \"Cellphone\", 6000),\n",
    "        (\"Normal\", \"Tablet\", 1500),\n",
    "        (\"Mini\", \"Tablet\", 5500),\n",
    "        (\"Mini\", \"Cellphone\", 5000),\n",
    "        (\"Foldable\", \"Cellphone\", 6500),\n",
    "        (\"Foldable\", \"Tablet\", 2500),\n",
    "        (\"Pro\", \"Cellphone\", 3000),\n",
    "        (\"Pro\", \"Tablet\", 4000),\n",
    "        (\"Pro Max\", \"Cellphone\", 4500)\n",
    "    ],\n",
    "    [\"product\", \"category\", \"revenue\"]\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "df.ai.transform(\"What is the best-selling product\").show()\n",
    "#example query\n",
    "#df.ai.transform(\"Pivot the data by product and the revenue for each product\").show()\n",
    "#df.ai.transform(\"Pivot the data by catagory and the revenue for each product\").show()\n",
    "#df.ai.transform(\"What are the best-selling and the second best-selling products in every category?\").show()\n",
    "#df.ai.transform(\"What is the difference between the revenue of each product and the revenue of the best-selling product in the same category of that product?\").show()\n",
    "task_time = time.time() - start_time\n",
    "\n",
    "print(f\"Init time: {init_time} seconds\")\n",
    "print(f\"Task time: {task_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4ec66a-3b8c-4a65-b948-8420b492333d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
